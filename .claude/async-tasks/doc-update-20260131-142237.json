{
  "type": "doc-update",
  "created_at": "2026-01-31T14:22:37.151373+00:00",
  "status": "pending",
  "commit_message": "feat(compound): upgrade memory system to v3 \u2014 higher signal capture and smarter consumption\n\nRedesign the compound memory system for richer, higher-signal cross-session learning:\n\n- Checkpoint template: require key_insight (>30 chars), search_terms (2-7 concept keywords),\n  and category enum (bugfix|gotcha|architecture|pattern|config|refactor)\n- Validation: enforce memory fields in standard path, warn in /go path\n- Auto-capture: model-provided search_terms as primary entities (not git diff),\n  LESSON-first content with truncated context, quality metadata\n- Event schema: top-level category field, hardened dedup (8-event lookback, 60-min window)\n- Context loader: 4-signal scoring (entity 35%, recency 30%, quality 20%, source 15%),\n  concept entity matching against stems/dirs, score-tiered injection budget (600/350/200 chars),\n  MIN_SCORE threshold (0.12), structured XML with tags attribute\n- Backward compatible: old events work via .get() defaults, age out via 90-day TTL\n\nCo-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>",
  "diff_content": "commit dd7c50cefb7237d8969401489c1c627a60e3bbe7\nAuthor: olivier-motium <243932812+olivier-motium@users.noreply.github.com>\nDate:   Sat Jan 31 15:22:36 2026 +0100\n\n    feat(compound): upgrade memory system to v3 \u2014 higher signal capture and smarter consumption\n    \n    Redesign the compound memory system for richer, higher-signal cross-session learning:\n    \n    - Checkpoint template: require key_insight (>30 chars), search_terms (2-7 concept keywords),\n      and category enum (bugfix|gotcha|architecture|pattern|config|refactor)\n    - Validation: enforce memory fields in standard path, warn in /go path\n    - Auto-capture: model-provided search_terms as primary entities (not git diff),\n      LESSON-first content with truncated context, quality metadata\n    - Event schema: top-level category field, hardened dedup (8-event lookback, 60-min window)\n    - Context loader: 4-signal scoring (entity 35%, recency 30%, quality 20%, source 15%),\n      concept entity matching against stems/dirs, score-tiered injection budget (600/350/200 chars),\n      MIN_SCORE threshold (0.12), structured XML with tags attribute\n    - Backward compatible: old events work via .get() defaults, age out via 90-day TTL\n    \n    Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>\n---\n config/hooks/_memory.py                 |  51 +++++-\n config/hooks/_sv_templates.py           |  29 +++-\n config/hooks/_sv_validators.py          | 112 +++++++++++-\n config/hooks/compound-context-loader.py | 295 +++++++++++++++++++++++++++-----\n config/hooks/stop-validator.py          |  77 +++++++--\n config/skills/compound/SKILL.md         |  82 ++++++---\n docs/index.md                           |  61 ++++++-\n 7 files changed, 616 insertions(+), 91 deletions(-)\n\ndiff --git a/config/hooks/_memory.py b/config/hooks/_memory.py\nindex 6b2576e..c6ac5e5 100644\n--- a/config/hooks/_memory.py\n+++ b/config/hooks/_memory.py\n@@ -139,6 +139,42 @@ def get_memory_dir(cwd: str) -> Path:\n     return memory_dir\n \n \n+# ============================================================================\n+# Dedup Guard\n+# ============================================================================\n+\n+\n+def _is_duplicate(event_dir: Path, content: str, window: int = 8) -> bool:\n+    \"\"\"Check if content duplicates a recent event (prefix hash + time window).\n+\n+    Compares MD5 of first 200 chars against last `window` events.\n+    Only considers matches within a 60-minute time window to catch\n+    stop-retry duplicates and cross-session duplicates from sticky sessions.\n+    \"\"\"\n+    prefix_hash = hashlib.md5(content[:200].encode()).hexdigest()\n+    manifest_path = event_dir.parent / MANIFEST_NAME\n+    try:\n+        manifest = json.loads(manifest_path.read_text())\n+        now = time.time()\n+        for eid in manifest.get(\"recent\", [])[:window]:\n+            evt = safe_read_event(event_dir / f\"{eid}.json\")\n+            if not evt:\n+                continue\n+            # Check content prefix match\n+            if hashlib.md5(evt.get(\"content\", \"\")[:200].encode()).hexdigest() != prefix_hash:\n+                continue\n+            # Check time window (60 minutes)\n+            evt_path = event_dir / f\"{eid}.json\"\n+            try:\n+                if now - evt_path.stat().st_mtime < 3600:\n+                    return True\n+            except OSError:\n+                continue\n+    except (json.JSONDecodeError, IOError, OSError):\n+        pass\n+    return False\n+\n+\n # ============================================================================\n # Event Operations\n # ============================================================================\n@@ -150,14 +186,26 @@ def append_event(\n     entities: list[str],\n     event_type: str = \"compound\",\n     source: str = \"compound\",\n+    category: str = \"session\",\n     meta: dict | None = None,\n-) -> Path:\n+) -> Path | None:\n     \"\"\"Append a new event to the store. Returns the event file path.\n \n+    Returns None if the event is a duplicate of a recent event.\n     Filename includes timestamp + PID + random suffix for uniqueness\n     without locking.\n     \"\"\"\n     event_dir = get_memory_dir(cwd)\n+\n+    # Dedup guard: skip if content matches a recent event within 60 minutes\n+    if _is_duplicate(event_dir, content):\n+        log_debug(\n+            \"Skipping duplicate event (content prefix matches recent event)\",\n+            hook_name=\"memory\",\n+            parsed_data={\"content_prefix\": content[:50]},\n+        )\n+        return None\n+\n     now = datetime.now(timezone.utc)\n     ts = now.strftime(\"%Y%m%dT%H%M%S\")\n     suffix = uuid4().hex[:6]\n@@ -170,6 +218,7 @@ def append_event(\n         \"content\": content,\n         \"entities\": entities,\n         \"source\": source,\n+        \"category\": category,\n         \"meta\": meta or {},\n     }\n \ndiff --git a/config/hooks/_sv_templates.py b/config/hooks/_sv_templates.py\nindex fa625b7..a6b4d29 100644\n--- a/config/hooks/_sv_templates.py\n+++ b/config/hooks/_sv_templates.py\n@@ -27,11 +27,14 @@ GO_CHECKPOINT_SCHEMA_TEMPLATE = \"\"\"{version_note}\n   \"self_report\": {{\n     \"is_job_complete\": false,                // Is the job ACTUALLY done?\n     \"code_changes_made\": false,              // Did you modify any code files?\n-    \"linters_pass\": false                    // (Only if code_changes_made) Did linters pass?\n+    \"linters_pass\": false,                   // (Only if code_changes_made) Did linters pass?\n+    \"category\": \"\"                           // REQUIRED: bugfix | gotcha | architecture | pattern | config | refactor\n   }},\n   \"reflection\": {{\n     \"what_was_done\": \"...\",                  // >20 chars - what you actually did\n-    \"what_remains\": \"none\"                   // Must be empty to allow stop\n+    \"what_remains\": \"none\",                  // Must be empty to allow stop\n+    \"key_insight\": \"...\",                    // >30 chars: reusable lesson for FUTURE sessions. NOT what you did \u2014 what you LEARNED.\n+    \"search_terms\": []                       // 2-7 concept keywords for memory retrieval. Tool names, error types, patterns. NOT file paths.\n   }}\n }}\"\"\"\n \n@@ -45,11 +48,14 @@ CHECKPOINT_SCHEMA_TEMPLATE = \"\"\"{version_note}\n     \"deployed_at_version\": \"\",              // Git version when deployed\n     \"linters_pass\": false,                  // Did all linters pass?\n     \"linters_pass_at_version\": \"\",          // Git version when linted\n-    \"is_job_complete\": false                // Is the job ACTUALLY done?\n+    \"is_job_complete\": false,               // Is the job ACTUALLY done?\n+    \"category\": \"\"                          // REQUIRED: bugfix | gotcha | architecture | pattern | config | refactor\n   }},\n   \"reflection\": {{\n     \"what_was_done\": \"...\",                 // Honest summary of work completed\n-    \"what_remains\": \"none\"                  // Must be empty to allow stop\n+    \"what_remains\": \"none\",                 // Must be empty to allow stop\n+    \"key_insight\": \"...\",                   // REQUIRED >30 chars: reusable lesson for FUTURE sessions. NOT what you did \u2014 what you LEARNED.\n+    \"search_terms\": []                      // REQUIRED 2-7 concept keywords for memory retrieval. Tool names, error types, patterns. NOT file paths.\n   }},\n   \"evidence\": {{\n     \"urls_tested\": [],                      // URLs you actually tested\n@@ -93,6 +99,21 @@ GUIDANCE_BLOCKS = {\n \"\"\",\n     \"what_remains\": \"\"\"\n   \u2192 You listed remaining work \u2014 do it!\n+\"\"\",\n+    \"key_insight\": \"\"\"\n+  \u2192 key_insight captures what FUTURE sessions should know \u2014 the reusable lesson\n+  \u2192 Must be >30 chars and different from what_was_done (it's what you LEARNED, not what you DID)\n+  \u2192 Example: \"macOS fsync() doesn't flush disk write cache; F_FULLFSYNC is required for crash safety\"\n+\"\"\",\n+    \"search_terms\": \"\"\"\n+  \u2192 search_terms are 2-7 concept keywords for memory retrieval\n+  \u2192 Include: tool names, error types, technique names, platform quirks\n+  \u2192 Do NOT include file paths (those are extracted automatically)\n+  \u2192 Example: [\"macOS\", \"fsync\", \"crash-safety\", \"atomic-write\"]\n+\"\"\",\n+    \"category\n\n... [truncated - diff too long]",
  "existing_docs": [
    "docs/architecture.md",
    "docs/analysis-persistent-memory-for-harnesses.md",
    "docs/index.md",
    "docs/memory-integration-analysis.md",
    "docs/philosophy.md",
    "docs/audiobook-the-amnesiac-architect.md",
    "README.md",
    ".claude/MEMORIES.md"
  ],
  "instructions": "\nDOCUMENTATION UPDATE TASK\n\nA commit was just made in an repair/build session. Your job is to:\n\n1. Analyze the diff to understand what changed\n2. Determine which documentation files need updating\n3. Update the relevant docs to reflect the changes\n\nCOMMIT MESSAGE:\nfeat(compound): upgrade memory system to v3 \u2014 higher signal capture and smarter consumption\n\nRedesign the compound memory system for richer, higher-signal cross-session learning:\n\n- Checkpoint template: require key_insight (>30 chars), search_terms (2-7 concept keywords),\n  and category enum (bugfix|gotcha|architecture|pattern|config|refactor)\n- Validation: enforce memory fields in standard path, warn in /go path\n- Auto-capture: model-provided search_terms as primary entities (not git diff),\n  LESSON-first content with truncated context, quality metadata\n- Event schema: top-level category field, hardened dedup (8-event lookback, 60-min window)\n- Context loader: 4-signal scoring (entity 35%, recency 30%, quality 20%, source 15%),\n  concept entity matching against stems/dirs, score-tiered injection budget (600/350/200 chars),\n  MIN_SCORE threshold (0.12), structured XML with tags attribute\n- Backward compatible: old events work via .get() defaults, age out via 90-day TTL\n\nCo-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>\n\nEXISTING DOCUMENTATION FILES:\n- docs/architecture.md\n- docs/analysis-persistent-memory-for-harnesses.md\n- docs/index.md\n- docs/memory-integration-analysis.md\n- docs/philosophy.md\n- docs/audiobook-the-amnesiac-architect.md\n- README.md\n- .claude/MEMORIES.md\n\nDIFF CONTENT:\ncommit dd7c50cefb7237d8969401489c1c627a60e3bbe7\nAuthor: olivier-motium <243932812+olivier-motium@users.noreply.github.com>\nDate:   Sat Jan 31 15:22:36 2026 +0100\n\n    feat(compound): upgrade memory system to v3 \u2014 higher signal capture and smarter consumption\n    \n    Redesign the compound memory system for richer, higher-signal cross-session learning:\n    \n    - Checkpoint template: require key_insight (>30 chars), search_terms (2-7 concept keywords),\n      and category enum (bugfix|gotcha|architecture|pattern|config|refactor)\n    - Validation: enforce memory fields in standard path, warn in /go path\n    - Auto-capture: model-provided search_terms as primary entities (not git diff),\n      LESSON-first content with truncated context, quality metadata\n    - Event schema: top-level category field, hardened dedup (8-event lookback, 60-min window)\n    - Context loader: 4-signal scoring (entity 35%, recency 30%, quality 20%, source 15%),\n      concept entity matching against stems/dirs, score-tiered injection budget (600/350/200 chars),\n      MIN_SCORE threshold (0.12), structured XML with tags attribute\n    - Backward compatible: old events work via .get() defaults, age out via 90-day TTL\n    \n    Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>\n---\n config/hooks/_memory.py                 |  51 +++++-\n config/hooks/_sv_templates.py           |  29 +++-\n config/hooks/_sv_validators.py          | 112 +++++++++++-\n config/hooks/compound-context-loader.py | 295 +++++++++++++++++++++++++++-----\n config/hooks/stop-validator.py          |  77 +++++++--\n config/skills/compound/SKILL.md         |  82 ++++++---\n docs/index.md                           |  61 ++++++-\n 7 files changed, 616 insertions(+), 91 deletions(-)\n\ndiff --git a/config/hooks/_memory.py b/config/hooks/_memory.py\nindex 6b2576e..c6ac5e5 100644\n--- a/config/hooks/_memory.py\n+++ b/config/hooks/_memory.py\n@@ -139,6 +139,42 @@ def get_memory_dir(cwd: str) -> Path:\n     return memory_dir\n \n \n+# ============================================================================\n+# Dedup Guard\n+# ============================================================================\n+\n+\n+def _is_duplicate(event_dir: Path, content: str, window: int = 8) -> bool:\n+    \"\"\"Check if content duplicates a recent event (prefix hash + time window).\n+\n+    Compares MD5 of first 200 chars against last `window` events.\n+    Only considers matches within a 60-minute time window to catch\n+    stop-retry duplicates and cross-session duplicates from sticky sessions.\n+    \"\"\"\n+    prefix_hash = hashlib.md5(content[:200].encode()).hexdigest()\n+    manifest_path = event_dir.parent / MANIFEST_NAME\n+    try:\n+        manifest = json.loads(manifest_path.read_text())\n+        now = time.time()\n+        for eid in manifest.get(\"recent\", [])[:window]:\n+            evt = safe_read_event(event_dir / f\"{eid}.json\")\n+            if not evt:\n+                continue\n+            # Check content prefix match\n+            if hashlib.md5(evt.get(\"content\", \"\")[:200].encode()).hexdigest() != prefix_hash:\n+                continue\n+            # Check time window (60 minutes)\n+            evt_path = event_dir / f\"{eid}.json\"\n+            try:\n+                if now - evt_path.stat().st_mtime < 3600:\n+                    return True\n+            except OSError:\n+                continue\n+    except (json.JSONDecodeError, IOError, OSError):\n+        pass\n+    return False\n+\n+\n # ============================================================================\n # Event Operations\n # ============================================================================\n@@ -150,14 +186,26 @@ def append_event(\n     entities: list[str],\n     event_type: str = \"compound\",\n     source: str = \"compound\",\n+    category: str = \"session\",\n     meta: dict | None = None,\n-) -> Path:\n+) -> Path | None:\n     \"\"\"Append a new event to the store. Returns the event file path.\n \n+    Returns None if the event is a duplicate of a recent event.\n     Filename includes timestamp + PID + random suffix for uniqueness\n     without locking.\n     \"\"\"\n     event_dir = get_memory_dir(cwd)\n+\n+    # Dedup guard: skip if content matches a recent event within 60 minutes\n+    if _is_duplicate(event_dir, content):\n+        log_debug(\n+            \"Skipping duplicate event (content prefix matches recent event)\",\n+            hook_name=\"memory\",\n+            parsed_data={\"content_prefix\": content[:50]},\n+        )\n+        return None\n+\n     now = datetime.now(timezone.utc)\n     ts = now.strftime(\"%Y%m%dT%H%M%S\")\n     suffix = uuid4().hex[:6]\n@@ -170,6 +218,7 @@ def append_event(\n         \"content\": content,\n         \"entities\": entities,\n         \"source\": source,\n+        \"category\": category,\n         \"meta\": meta or {},\n     }\n \ndiff --git a/config/hooks/_sv_templates.py b/config/hooks/_sv_templates.py\nindex fa625b7..a6b4d29 100644\n--- a/config/hooks/_sv_templates.py\n+++ b/config/hooks/_sv_templates.py\n@@ -27,11 +27,14 @@ GO_CHECKPOINT_SCHEMA_TEMPLATE = \"\"\"{version_note}\n   \"self_report\": {{\n     \"is_job_complete\": false,                // Is the job ACTUALLY done?\n     \"code_changes_made\": false,              // Did you modify any code files?\n-    \"linters_pass\": false                    // (Only if code_changes_made) Did linters pass?\n+    \"linters_pass\": false,                   // (Only if code_changes_made) Did linters pass?\n+    \"category\": \"\"                           // REQUIRED: bugfix | gotcha | architecture | pattern | config | refactor\n   }},\n   \"reflection\": {{\n     \"what_was_done\": \"...\",                  // >20 chars - what you actually did\n-    \"what_remains\": \"none\"                   // Must be empty to allow stop\n+    \"what_remains\": \"none\",                  // Must be empty to allow stop\n+    \"key_insight\": \"...\",                    // >30 chars: reusable lesson for FUTURE sessions. NOT what you did \u2014 what you LEARNED.\n+    \"search_terms\": []                       // 2-7 concept keywords for memory retrieval. Tool names, error types, patterns. NOT file paths.\n   }}\n }}\"\"\"\n \n@@ -45,11 +48,14 @@ CHECKPOINT_SCHEMA_TEMPLATE = \"\"\"{version_note}\n     \"deployed_at_version\": \"\",              // Git version when deployed\n     \"linters_pass\": false,                  // Did all linters pass?\n     \"linters_pass_at_version\": \"\",          // Git version when linted\n-    \"is_job_complete\": false                // Is the job ACTUALLY done?\n+    \"is_job_complete\": false,               // Is the job ACTUALLY done?\n+    \"category\": \"\"                          // REQUIRED: bugfix | gotcha | architecture | pattern | config | refactor\n   }},\n   \"reflection\": {{\n     \"what_was_done\": \"...\",                 // Honest summary of work completed\n-    \"what_remains\": \"none\"                  // Must be empty to allow stop\n+    \"what_remains\": \"none\",                 // Must be empty to allow stop\n+    \"key_insight\": \"...\",                   // REQUIRED >30 chars: reusable lesson for FUTURE sessions. NOT what you did \u2014 what you LEARNED.\n+    \"search_terms\": []                      // REQUIRED 2-7 concept keywords for memory retrieval. Tool names, error types, patterns. NOT file paths.\n   }},\n   \"evidence\": {{\n     \"urls_tested\": [],                      // URLs you actually tested\n@@ -93,6 +99,21 @@ GUIDANCE_BLOCKS = {\n \"\"\",\n     \"what_remains\": \"\"\"\n   \u2192 You listed remaining work \u2014 do it!\n+\"\"\",\n+    \"key_insight\": \"\"\"\n+  \u2192 key_insight captures what FUTURE sessions should know \u2014 the reusable lesson\n+  \u2192 Must be >30 chars and different from what_was_done (it's what you LEARNED, not what you DID)\n+  \u2192 Example: \"macOS fsync() doesn't flush disk write cache; F_FULLFSYNC is required for crash safety\"\n+\"\"\",\n+    \"search_terms\": \"\"\"\n+  \u2192 search_terms are 2-7 concept keywords for memory retrieval\n+  \u2192 Include: tool names, error types, technique names, platform quirks\n+  \u2192 Do NOT include file paths (those are extracted automatically)\n+  \u2192 Example: [\"macOS\", \"fsync\", \"crash-safety\", \"atomic-write\"]\n+\"\"\",\n+    \"category\n\n... [truncated - diff too long]\n\nINSTRUCTIONS:\n- Only update docs that are actually affected by this change\n- Keep updates concise and accurate\n- Don't add unnecessary documentation\n- If the change is purely code (no architectural/API changes), you may skip doc updates\n- Focus on: API changes, new features, architectural decisions, configuration changes\n\nUse the /heavy skill if you need multiple perspectives on what to document.\n"
}