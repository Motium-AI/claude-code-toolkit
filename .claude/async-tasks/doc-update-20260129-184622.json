{
  "type": "doc-update",
  "created_at": "2026-01-29T18:46:22.922795+00:00",
  "status": "pending",
  "commit_message": "feat(heavy): Fix AI context delivery to agents + add Exa MCP\n\nProblem: Agents in /heavy interpreted \"AI\" as \"ML\" because they couldn't\naccess the Research Context section - line 229 referenced \"Research Context\nabove\" but Task-spawned agents only receive their prompt string.\n\nChanges:\n- Add Research Context section with AI terminology definition (frontier\n  models: Opus 4.5, GPT-5.2, Gemini-3-Flash, o3, DeepSeek-V3)\n- Add Source Authority Hierarchy (Tier 1/2/3 + AVOID list)\n- Add Search Query Patterns table with construction rules\n- Add Exa AI MCP integration guidance\n- Fix all 9 agent prompt templates to embed source rules directly\n  instead of referencing inaccessible SKILL.md content\n- Add CRITICAL reminders with current model names to every template\n- Replace generic search instructions with specific Tier 1 sources\n  and AVOID lists (Forbes, TechCrunch, LinkedIn, SEO farms)\n\nCo-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>",
  "diff_content": "commit 2c5dd029a99bbfc57137316c7a2f714c0cc0dcbb\nAuthor: olivier-motium <243932812+olivier-motium@users.noreply.github.com>\nDate:   Thu Jan 29 19:46:22 2026 +0100\n\n    feat(heavy): Fix AI context delivery to agents + add Exa MCP\n    \n    Problem: Agents in /heavy interpreted \"AI\" as \"ML\" because they couldn't\n    access the Research Context section - line 229 referenced \"Research Context\n    above\" but Task-spawned agents only receive their prompt string.\n    \n    Changes:\n    - Add Research Context section with AI terminology definition (frontier\n      models: Opus 4.5, GPT-5.2, Gemini-3-Flash, o3, DeepSeek-V3)\n    - Add Source Authority Hierarchy (Tier 1/2/3 + AVOID list)\n    - Add Search Query Patterns table with construction rules\n    - Add Exa AI MCP integration guidance\n    - Fix all 9 agent prompt templates to embed source rules directly\n      instead of referencing inaccessible SKILL.md content\n    - Add CRITICAL reminders with current model names to every template\n    - Replace generic search instructions with specific Tier 1 sources\n      and AVOID lists (Forbes, TechCrunch, LinkedIn, SEO farms)\n    \n    Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>\n---\n config/skills/heavy/SKILL.md | 116 +++++++++++++++++++++++++++++++++++++------\n 1 file changed, 102 insertions(+), 14 deletions(-)\n\ndiff --git a/config/skills/heavy/SKILL.md b/config/skills/heavy/SKILL.md\nindex 51d472f..40ada97 100644\n--- a/config/skills/heavy/SKILL.md\n+++ b/config/skills/heavy/SKILL.md\n@@ -70,6 +70,78 @@ Vendor documentation lives in the repo. Search for it before inventing approache\n Patterns already exist in the codebase. Find them before proposing new ones.\n ```\n \n+## Research Context (CRITICAL for All Agents)\n+\n+### Terminology: \"AI\" Means Frontier Generative AI\n+\n+When the user says \"AI\" in this context, they mean:\n+- **Frontier models**: Claude Opus 4.5, GPT-5.2, Gemini-3-Flash, o3, DeepSeek-V3, etc.\n+- **Agentic systems**: Tool-using LLMs, multi-agent orchestration, MCP\n+- **Production LLM patterns**: Structured outputs, prompt engineering, evals\n+- **NOT**: Traditional ML, sklearn, statistical models, 2020-era chatbots\n+\n+Search queries should reflect this. \"AI best practices\" returns stale content; \"Claude agent patterns 2025\" returns current content.\n+\n+### Source Authority Hierarchy\n+\n+**Tier 1 - Most Authoritative (prefer these):**\n+- GitHub repos with working code:\n+  - `anthropics/*` (Claude patterns, agent SDK, MCP)\n+  - `pydantic/pydantic-ai` (structured outputs, multi-model)\n+  - `openai/*` (agents SDK, swarm, evals)\n+  - `langchain-ai/langgraph` (agentic workflows)\n+  - `vercel/ai` (AI SDK patterns)\n+  - `run-llama/llama_index` (RAG, agents)\n+- Official docs: docs.anthropic.com, ai.google.dev, platform.openai.com\n+- Practitioner blogs with code: Simon Willison, Hamel Husain, Eugene Yan, swyx\n+\n+**Tier 2 - Good for Patterns:**\n+- GitHub trending: 500+ stars, updated in last 6 months, has working examples\n+- Substacks: Latent Space, The Batch, AI Engineer newsletter\n+- X/Twitter: Only practitioners who ship (check for linked repos)\n+\n+**Tier 3 - Use with Caution:**\n+- Hacker News (signal in comments, filter for links to code)\n+- Medium/dev.to (verify author has GitHub repos)\n+\n+**AVOID - Likely Stale or Slop:**\n+- Business press (Forbes AI, TechCrunch think pieces, VentureBeat)\n+- Academic papers older than 6 months (field moves too fast now)\n+- SEO tutorial farms (Analytics Vidhya, GeeksforGeeks AI sections)\n+- \"Top 10 AI tools\" listicles\n+- LinkedIn AI influencer posts\n+- Generic \"AI best practices\" content without code\n+\n+### Search Tool Preference\n+\n+If Exa AI MCP is available (tools like `web_search_exa`, `get_code_context_exa`), prefer it over generic WebSearch for:\n+- **Code search**: `get_code_context_exa` finds GitHub, StackOverflow, docs directly\n+- **Technical research**: `web_search_exa` returns cleaner, more technical content\n+- **Company research**: `company_research_exa` for competitor/vendor analysis\n+\n+Configure Exa MCP: `claude mcp add --transport http exa https://mcp.exa.ai/mcp`\n+\n+### Search Query Patterns That Work\n+\n+| Bad Query (stale results) | Good Query (current results) |\n+|---------------------------|------------------------------|\n+| \"AI best practices\" | \"Claude Opus agent patterns 2026\" |\n+| \"LLM implementation\" | \"PydanticAI production site:github.com\" |\n+| \"AI architecture\" | \"multi-agent MCP orchestration example\" |\n+| \"machine learning ops\" | \"LLM observability Logfire tracing\" |\n+| \"chatbot development\" | \"structured outputs tool calling Claude\" |\n+| \"AI agents\" | \"agentic workflows langgraph anthropic\" |\n+| \"prompt engineering\" | \"Claude prompt optimization evals\" |\n+\n+**Query construction rules:**\n+1. **Use current year**: \"2026\" or \"2025\" (never older)\n+2. **Name specific models**: \"Opus 4.5\", \"GPT-5.2\", \"Gemini-3-Flash\" not generic \"AI\"\n+3. **Name specific frameworks**: \"PydanticAI\", \"LangGraph\", \"Claude Agent SDK\"\n+4. **Target GitHub**: `site:github.com [topic]` or use Exa's `get_code_context_exa`\n+5. **Add \"production\" or \"example\"**: Filters out tutorial slop\n+\n+**If using Exa MCP**: Use `get_code_context_exa` for code patterns - it searches GitHub, StackOverflow, and docs directly with better signal-to-noise than generic web search.\n+\n ## Execution Strategy\n \n ### Round 1: Breadth (Launch 6 Parallel Agents)\n@@ -154,9 +226,15 @@ Infra: Azure Container Apps + GitHub Actions + Terraform | AI: Multi-model (Gemi\n You have FULL TOOL ACCESS. Use it.\n \n 1. **Search the codebase** for existing patterns (Glob for files, Grep for code, Read for details)\n-2. **Search the web** for current best practices and failure cases\n+2. **Search the web** following these source rules:\n+   - **Tier 1 (prefer)**: anthropics/*, pydantic/pydantic-ai, openai/*, docs.anthropic.com, Simon Willison, Hamel Husain\n+   - **AVOID**: Forbes, TechCrunch, VentureBeat, LinkedIn, academic papers >6mo, SEO farms (Analytics Vidhya, GeeksforGeeks)\n+   - **Query pattern**: \"Claude agent patterns 2026\" not \"AI best practices\" \u2014 add year, specific tech, site:github.com\n+   - **If Exa available**: Use `get_code_context_exa` for GitHub/code search, `web_search_exa` for practitioner content\n 3. **Search vendor docs** in the repo (PydanticAI, Logfire, TanStack, Clerk)\n \n+**CRITICAL**: \"AI\" means frontier generative AI (Opus 4.5, GPT-5.2, Gemini-3-Flash, o3, DeepSeek-V3), NOT traditional ML/sklearn.\n+\n Don't reason from priors. Find evidence.\n \n ## Your Mission\n@@ -201,10 +279,12 @@ Infra: Azure Container Apps + GitHub Actions + Terraform | AI: Multi-model (Gemi\n \n You have FULL TOOL ACCESS. Use it to improve the implementation.\n \n-1. **Search for pitfalls in this approach**: WebSearch for \"[approach] best practices\", \"[approach] common mistakes\"\n-2. **Find successful implementations**: How have others done this WELL?\n+1. **Search for pitfalls**: WebSearch for \"[approach] gotchas 2025\", \"site:github.com [approach] issues\"\n+2. **Find successful implementations**: Search Tier 1 sources (anthropics/*, pydantic/pydantic-ai repos)\n 3. **Check local constraints**: Grep/Read to understand what existing patterns to honor\n \n+**CRITICAL**: \"AI\" means frontier generative AI (Opus 4.5, GPT-5.2, Gemini-3-Flash, o3). Search for specific patterns not generic \"AI best practices\".\n+\n IMPORTANT: You are NOT questioning WHETHER to pursue the goal. You are helping achieve it BETTER.\n \n ## Your Mission\n@@ -241,10 +321,12 @@ Infra: Azure Container Apps + GitHub Actions + Terraform | AI: Multi-model (Gemi\n \n You have FULL TOOL ACCESS. Use it to build your case.\n \n-1. **Search for failure cases**: WebSearch for \"[topic] failures\", \"[topic] post-mortem\", \"why [topic] failed\"\n-2. **Find counterexamples**: Where did the opposite approach succeed?\n+1. **Search for failure cases**: WebSearch for \"[topic] failures 2025 site:github.com\", \"[topic] post-mortem\"\n+2. **Find counterexamples**: Search practitioner blogs (Simon Willison, Hamel Husain) for real-world failures\n 3. **Check loca\n\n... [truncated - diff too long]",
  "existing_docs": [
    "docs/architecture.md",
    "docs/index.md",
    "docs/philosophy.md",
    "README.md",
    ".claude/MEMORIES.md"
  ],
  "instructions": "\nDOCUMENTATION UPDATE TASK\n\nA commit was just made in an appfix/godo session. Your job is to:\n\n1. Analyze the diff to understand what changed\n2. Determine which documentation files need updating\n3. Update the relevant docs to reflect the changes\n\nCOMMIT MESSAGE:\nfeat(heavy): Fix AI context delivery to agents + add Exa MCP\n\nProblem: Agents in /heavy interpreted \"AI\" as \"ML\" because they couldn't\naccess the Research Context section - line 229 referenced \"Research Context\nabove\" but Task-spawned agents only receive their prompt string.\n\nChanges:\n- Add Research Context section with AI terminology definition (frontier\n  models: Opus 4.5, GPT-5.2, Gemini-3-Flash, o3, DeepSeek-V3)\n- Add Source Authority Hierarchy (Tier 1/2/3 + AVOID list)\n- Add Search Query Patterns table with construction rules\n- Add Exa AI MCP integration guidance\n- Fix all 9 agent prompt templates to embed source rules directly\n  instead of referencing inaccessible SKILL.md content\n- Add CRITICAL reminders with current model names to every template\n- Replace generic search instructions with specific Tier 1 sources\n  and AVOID lists (Forbes, TechCrunch, LinkedIn, SEO farms)\n\nCo-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>\n\nEXISTING DOCUMENTATION FILES:\n- docs/architecture.md\n- docs/index.md\n- docs/philosophy.md\n- README.md\n- .claude/MEMORIES.md\n\nDIFF CONTENT:\ncommit 2c5dd029a99bbfc57137316c7a2f714c0cc0dcbb\nAuthor: olivier-motium <243932812+olivier-motium@users.noreply.github.com>\nDate:   Thu Jan 29 19:46:22 2026 +0100\n\n    feat(heavy): Fix AI context delivery to agents + add Exa MCP\n    \n    Problem: Agents in /heavy interpreted \"AI\" as \"ML\" because they couldn't\n    access the Research Context section - line 229 referenced \"Research Context\n    above\" but Task-spawned agents only receive their prompt string.\n    \n    Changes:\n    - Add Research Context section with AI terminology definition (frontier\n      models: Opus 4.5, GPT-5.2, Gemini-3-Flash, o3, DeepSeek-V3)\n    - Add Source Authority Hierarchy (Tier 1/2/3 + AVOID list)\n    - Add Search Query Patterns table with construction rules\n    - Add Exa AI MCP integration guidance\n    - Fix all 9 agent prompt templates to embed source rules directly\n      instead of referencing inaccessible SKILL.md content\n    - Add CRITICAL reminders with current model names to every template\n    - Replace generic search instructions with specific Tier 1 sources\n      and AVOID lists (Forbes, TechCrunch, LinkedIn, SEO farms)\n    \n    Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>\n---\n config/skills/heavy/SKILL.md | 116 +++++++++++++++++++++++++++++++++++++------\n 1 file changed, 102 insertions(+), 14 deletions(-)\n\ndiff --git a/config/skills/heavy/SKILL.md b/config/skills/heavy/SKILL.md\nindex 51d472f..40ada97 100644\n--- a/config/skills/heavy/SKILL.md\n+++ b/config/skills/heavy/SKILL.md\n@@ -70,6 +70,78 @@ Vendor documentation lives in the repo. Search for it before inventing approache\n Patterns already exist in the codebase. Find them before proposing new ones.\n ```\n \n+## Research Context (CRITICAL for All Agents)\n+\n+### Terminology: \"AI\" Means Frontier Generative AI\n+\n+When the user says \"AI\" in this context, they mean:\n+- **Frontier models**: Claude Opus 4.5, GPT-5.2, Gemini-3-Flash, o3, DeepSeek-V3, etc.\n+- **Agentic systems**: Tool-using LLMs, multi-agent orchestration, MCP\n+- **Production LLM patterns**: Structured outputs, prompt engineering, evals\n+- **NOT**: Traditional ML, sklearn, statistical models, 2020-era chatbots\n+\n+Search queries should reflect this. \"AI best practices\" returns stale content; \"Claude agent patterns 2025\" returns current content.\n+\n+### Source Authority Hierarchy\n+\n+**Tier 1 - Most Authoritative (prefer these):**\n+- GitHub repos with working code:\n+  - `anthropics/*` (Claude patterns, agent SDK, MCP)\n+  - `pydantic/pydantic-ai` (structured outputs, multi-model)\n+  - `openai/*` (agents SDK, swarm, evals)\n+  - `langchain-ai/langgraph` (agentic workflows)\n+  - `vercel/ai` (AI SDK patterns)\n+  - `run-llama/llama_index` (RAG, agents)\n+- Official docs: docs.anthropic.com, ai.google.dev, platform.openai.com\n+- Practitioner blogs with code: Simon Willison, Hamel Husain, Eugene Yan, swyx\n+\n+**Tier 2 - Good for Patterns:**\n+- GitHub trending: 500+ stars, updated in last 6 months, has working examples\n+- Substacks: Latent Space, The Batch, AI Engineer newsletter\n+- X/Twitter: Only practitioners who ship (check for linked repos)\n+\n+**Tier 3 - Use with Caution:**\n+- Hacker News (signal in comments, filter for links to code)\n+- Medium/dev.to (verify author has GitHub repos)\n+\n+**AVOID - Likely Stale or Slop:**\n+- Business press (Forbes AI, TechCrunch think pieces, VentureBeat)\n+- Academic papers older than 6 months (field moves too fast now)\n+- SEO tutorial farms (Analytics Vidhya, GeeksforGeeks AI sections)\n+- \"Top 10 AI tools\" listicles\n+- LinkedIn AI influencer posts\n+- Generic \"AI best practices\" content without code\n+\n+### Search Tool Preference\n+\n+If Exa AI MCP is available (tools like `web_search_exa`, `get_code_context_exa`), prefer it over generic WebSearch for:\n+- **Code search**: `get_code_context_exa` finds GitHub, StackOverflow, docs directly\n+- **Technical research**: `web_search_exa` returns cleaner, more technical content\n+- **Company research**: `company_research_exa` for competitor/vendor analysis\n+\n+Configure Exa MCP: `claude mcp add --transport http exa https://mcp.exa.ai/mcp`\n+\n+### Search Query Patterns That Work\n+\n+| Bad Query (stale results) | Good Query (current results) |\n+|---------------------------|------------------------------|\n+| \"AI best practices\" | \"Claude Opus agent patterns 2026\" |\n+| \"LLM implementation\" | \"PydanticAI production site:github.com\" |\n+| \"AI architecture\" | \"multi-agent MCP orchestration example\" |\n+| \"machine learning ops\" | \"LLM observability Logfire tracing\" |\n+| \"chatbot development\" | \"structured outputs tool calling Claude\" |\n+| \"AI agents\" | \"agentic workflows langgraph anthropic\" |\n+| \"prompt engineering\" | \"Claude prompt optimization evals\" |\n+\n+**Query construction rules:**\n+1. **Use current year**: \"2026\" or \"2025\" (never older)\n+2. **Name specific models**: \"Opus 4.5\", \"GPT-5.2\", \"Gemini-3-Flash\" not generic \"AI\"\n+3. **Name specific frameworks**: \"PydanticAI\", \"LangGraph\", \"Claude Agent SDK\"\n+4. **Target GitHub**: `site:github.com [topic]` or use Exa's `get_code_context_exa`\n+5. **Add \"production\" or \"example\"**: Filters out tutorial slop\n+\n+**If using Exa MCP**: Use `get_code_context_exa` for code patterns - it searches GitHub, StackOverflow, and docs directly with better signal-to-noise than generic web search.\n+\n ## Execution Strategy\n \n ### Round 1: Breadth (Launch 6 Parallel Agents)\n@@ -154,9 +226,15 @@ Infra: Azure Container Apps + GitHub Actions + Terraform | AI: Multi-model (Gemi\n You have FULL TOOL ACCESS. Use it.\n \n 1. **Search the codebase** for existing patterns (Glob for files, Grep for code, Read for details)\n-2. **Search the web** for current best practices and failure cases\n+2. **Search the web** following these source rules:\n+   - **Tier 1 (prefer)**: anthropics/*, pydantic/pydantic-ai, openai/*, docs.anthropic.com, Simon Willison, Hamel Husain\n+   - **AVOID**: Forbes, TechCrunch, VentureBeat, LinkedIn, academic papers >6mo, SEO farms (Analytics Vidhya, GeeksforGeeks)\n+   - **Query pattern**: \"Claude agent patterns 2026\" not \"AI best practices\" \u2014 add year, specific tech, site:github.com\n+   - **If Exa available**: Use `get_code_context_exa` for GitHub/code search, `web_search_exa` for practitioner content\n 3. **Search vendor docs** in the repo (PydanticAI, Logfire, TanStack, Clerk)\n \n+**CRITICAL**: \"AI\" means frontier generative AI (Opus 4.5, GPT-5.2, Gemini-3-Flash, o3, DeepSeek-V3), NOT traditional ML/sklearn.\n+\n Don't reason from priors. Find evidence.\n \n ## Your Mission\n@@ -201,10 +279,12 @@ Infra: Azure Container Apps + GitHub Actions + Terraform | AI: Multi-model (Gemi\n \n You have FULL TOOL ACCESS. Use it to improve the implementation.\n \n-1. **Search for pitfalls in this approach**: WebSearch for \"[approach] best practices\", \"[approach] common mistakes\"\n-2. **Find successful implementations**: How have others done this WELL?\n+1. **Search for pitfalls**: WebSearch for \"[approach] gotchas 2025\", \"site:github.com [approach] issues\"\n+2. **Find successful implementations**: Search Tier 1 sources (anthropics/*, pydantic/pydantic-ai repos)\n 3. **Check local constraints**: Grep/Read to understand what existing patterns to honor\n \n+**CRITICAL**: \"AI\" means frontier generative AI (Opus 4.5, GPT-5.2, Gemini-3-Flash, o3). Search for specific patterns not generic \"AI best practices\".\n+\n IMPORTANT: You are NOT questioning WHETHER to pursue the goal. You are helping achieve it BETTER.\n \n ## Your Mission\n@@ -241,10 +321,12 @@ Infra: Azure Container Apps + GitHub Actions + Terraform | AI: Multi-model (Gemi\n \n You have FULL TOOL ACCESS. Use it to build your case.\n \n-1. **Search for failure cases**: WebSearch for \"[topic] failures\", \"[topic] post-mortem\", \"why [topic] failed\"\n-2. **Find counterexamples**: Where did the opposite approach succeed?\n+1. **Search for failure cases**: WebSearch for \"[topic] failures 2025 site:github.com\", \"[topic] post-mortem\"\n+2. **Find counterexamples**: Search practitioner blogs (Simon Willison, Hamel Husain) for real-world failures\n 3. **Check loca\n\n... [truncated - diff too long]\n\nINSTRUCTIONS:\n- Only update docs that are actually affected by this change\n- Keep updates concise and accurate\n- Don't add unnecessary documentation\n- If the change is purely code (no architectural/API changes), you may skip doc updates\n- Focus on: API changes, new features, architectural decisions, configuration changes\n\nUse the /heavy skill if you need multiple perspectives on what to document.\n"
}