{
  "type": "doc-update",
  "created_at": "2026-01-31T00:36:24.923441+00:00",
  "status": "pending",
  "commit_message": "feat(compound): implement Phases 2-3 of Compound Memory System\n\n- Add compound-context-loader.py SessionStart hook for context injection\n- Register hook in settings.json (after session-snapshot, before read-docs)\n- Add /compound prompt to stop-validator (when code_changes_made=true)\n- Add async-tasks cleanup to session-snapshot (>7 days old)\n- Fix PID-scoped checkpoint cleanup with glob + is_pid_alive check\n\nThe compound memory system now has full infrastructure:\n- Phase 1: /compound skill for capturing solutions (done in 36fa2eb)\n- Phase 1.5: /build grep integration (done in 36fa2eb)\n- Phase 2: SessionStart context injection (this commit)\n- Phase 3: Automation prompts and cleanup (this commit)\n\nCo-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>",
  "diff_content": "commit 17883fdd208098c7bd4242cdb61743bfacde3ae4\nAuthor: olivier-motium <243932812+olivier-motium@users.noreply.github.com>\nDate:   Sat Jan 31 01:36:24 2026 +0100\n\n    feat(compound): implement Phases 2-3 of Compound Memory System\n    \n    - Add compound-context-loader.py SessionStart hook for context injection\n    - Register hook in settings.json (after session-snapshot, before read-docs)\n    - Add /compound prompt to stop-validator (when code_changes_made=true)\n    - Add async-tasks cleanup to session-snapshot (>7 days old)\n    - Fix PID-scoped checkpoint cleanup with glob + is_pid_alive check\n    \n    The compound memory system now has full infrastructure:\n    - Phase 1: /compound skill for capturing solutions (done in 36fa2eb)\n    - Phase 1.5: /build grep integration (done in 36fa2eb)\n    - Phase 2: SessionStart context injection (this commit)\n    - Phase 3: Automation prompts and cleanup (this commit)\n    \n    Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>\n---\n config/hooks/_state.py                  |  24 ++++++--\n config/hooks/compound-context-loader.py | 103 ++++++++++++++++++++++++++++++++\n config/hooks/session-snapshot.py        |  22 +++++++\n config/hooks/stop-validator.py          |  16 +++++\n config/settings.json                    |  10 ++++\n 5 files changed, 171 insertions(+), 4 deletions(-)\n\ndiff --git a/config/hooks/_state.py b/config/hooks/_state.py\nindex a40531e..3c9afb7 100644\n--- a/config/hooks/_state.py\n+++ b/config/hooks/_state.py\n@@ -14,7 +14,7 @@ import os\n from datetime import datetime, timezone\n from pathlib import Path\n \n-from _common import is_state_expired, is_state_for_session\n+from _common import is_state_expired, is_state_for_session, is_pid_alive\n \n \n # ============================================================================\n@@ -491,10 +491,13 @@ def cleanup_expired_state(cwd: str, current_session_id: str = \"\") -> list[str]:\n \n \n def cleanup_checkpoint_only(cwd: str) -> list[str]:\n-    \"\"\"Delete ONLY the completion checkpoint file. Leave mode state intact.\n+    \"\"\"Delete ONLY the completion checkpoint file(s). Leave mode state intact.\n \n     This is the sticky session replacement for cleanup_autonomous_state\n     at task boundaries.\n+\n+    Handles PID-scoped checkpoint files (e.g., completion-checkpoint.12345.json)\n+    by checking if the PID is still alive before deleting.\n     \"\"\"\n     deleted = []\n     if not cwd:\n@@ -504,8 +507,21 @@ def cleanup_checkpoint_only(cwd: str) -> list[str]:\n     if not claude_dir.exists():\n         return deleted\n \n-    checkpoint_path = claude_dir / \"completion-checkpoint.json\"\n-    if checkpoint_path.exists():\n+    # Use glob to find all checkpoint variants (including PID-scoped)\n+    for checkpoint_path in claude_dir.glob(\"completion-checkpoint*.json\"):\n+        name = checkpoint_path.name\n+\n+        # Check for PID-scoped files (e.g., completion-checkpoint.12345.json)\n+        if name != \"completion-checkpoint.json\":\n+            try:\n+                # Extract PID from filename\n+                pid_str = name.replace(\"completion-checkpoint.\", \"\").replace(\".json\", \"\")\n+                pid = int(pid_str)\n+                if is_pid_alive(pid):\n+                    continue  # Skip - belongs to active session\n+            except ValueError:\n+                pass  # Not a valid PID format, safe to delete\n+\n         try:\n             checkpoint_path.unlink()\n             deleted.append(str(checkpoint_path))\ndiff --git a/config/hooks/compound-context-loader.py b/config/hooks/compound-context-loader.py\nnew file mode 100644\nindex 0000000..d55abbf\n--- /dev/null\n+++ b/config/hooks/compound-context-loader.py\n@@ -0,0 +1,103 @@\n+#!/usr/bin/env python3\n+\"\"\"\n+Compound Context Loader - SessionStart Hook\n+\n+Injects relevant solutions from docs/solutions/ at session start.\n+Gracefully exits if no solutions directory exists.\n+\n+Part of the Compound Memory System that enables cross-session learning.\n+\"\"\"\n+\n+from __future__ import annotations\n+\n+import json\n+import sys\n+from pathlib import Path\n+\n+# Add hooks directory to path for shared imports\n+sys.path.insert(0, str(Path(__file__).parent))\n+\n+from _common import log_debug\n+\n+MAX_SOLUTIONS = 2\n+MAX_CHARS = 2000\n+\n+\n+def main():\n+    input_data = json.loads(sys.stdin.read() or \"{}\")\n+    cwd = input_data.get(\"cwd\", \"\")\n+\n+    if not cwd:\n+        sys.exit(0)\n+\n+    solutions_dir = Path(cwd) / \"docs\" / \"solutions\"\n+    if not solutions_dir.exists():\n+        sys.exit(0)\n+\n+    # Find all solution markdown files\n+    solution_files = []\n+    for md_file in solutions_dir.rglob(\"*.md\"):\n+        # Skip .gitkeep and other non-solution files\n+        if md_file.name.startswith(\".\") or md_file.name == \".gitkeep\":\n+            continue\n+        try:\n+            mtime = md_file.stat().st_mtime\n+            solution_files.append((mtime, md_file))\n+        except OSError:\n+            continue\n+\n+    if not solution_files:\n+        log_debug(\n+            \"No solution files found\",\n+            hook_name=\"compound-context-loader\",\n+            parsed_data={\"solutions_dir\": str(solutions_dir)},\n+        )\n+        sys.exit(0)\n+\n+    # Sort by mtime (most recent first), take top N\n+    solution_files.sort(reverse=True, key=lambda x: x[0])\n+    recent = solution_files[:MAX_SOLUTIONS]\n+\n+    # Build context summary\n+    summaries = []\n+    for _, path in recent:\n+        try:\n+            content = path.read_text()\n+            # Extract title from frontmatter or first heading\n+            title = path.stem.replace(\"-\", \" \").title()\n+            for line in content.split(\"\\n\"):\n+                if line.startswith(\"title:\"):\n+                    title = line.split(\":\", 1)[1].strip().strip(\"\\\"'\")\n+                    break\n+                if line.startswith(\"# \"):\n+                    title = line[2:].strip()\n+                    break\n+\n+            category = path.parent.name\n+            summaries.append(f\"- [{category}] {title}\")\n+        except (IOError, OSError):\n+            continue\n+\n+    if not summaries:\n+        sys.exit(0)\n+\n+    # Format output (plain text, not JSON - SessionStart hooks use plain print)\n+    output = \"[compound-context-loader] Recent solutions in docs/solutions/:\\n\"\n+    output += \"\\n\".join(summaries)\n+    output += \"\\n\\nRun `grep -riwl 'keyword' docs/solutions/` to find relevant fixes.\"\n+\n+    if len(output) > MAX_CHARS:\n+        output = output[: MAX_CHARS - 3] + \"...\"\n+\n+    log_debug(\n+        \"Injecting solution context\",\n+        hook_name=\"compound-context-loader\",\n+        parsed_data={\"solutions_count\": len(summaries), \"output_chars\": len(output)},\n+    )\n+\n+    print(output)\n+    sys.exit(0)\n+\n+\n+if __name__ == \"__main__\":\n+    main()\ndiff --git a/config/hooks/session-snapshot.py b/config/hooks/session-snapshot.py\nindex 9451a6e..bb25f08 100755\n--- a/config/hooks/session-snapshot.py\n+++ b/config/hooks/session-snapshot.py\n@@ -169,6 +169,28 @@ def main():\n     except ImportError:\n         pass  # worktree-manager not available\n \n+    # 5. Clean up stale async-tasks files (older than 7 days)\n+    import time\n+\n+    async_tasks_dir = claude_dir / \"async-tasks\"\n+    if async_tasks_dir.exists():\n+        seven_days_ago = time.time() - (7 * 24 * 60 * 60)\n+        cleaned_tasks = []\n+        for task_file in async_tasks_dir.glob(\"*.json\"):\n+            try:\n+                if task_file.stat().st_mtime < seven_days_ago:\n+                    task_file.unlink()\n+                    cleaned_tasks.append(task_file.name)\n+            except (IOError, OSError):\n+                continue\n+        if cleaned_tasks:\n+            log_debug(\n+                \"Cleaned up stale async-tasks\",\n+                hook_name=\"session-snapshot\",\n+                parsed_data={\"cleaned\": len(cleaned_tasks)},\n+            )\n+            print(f\"[session-snapshot] Cleaned up {len(cleaned_tasks)} stale async-task(s).\")\n+\n     sys.exit(0)\n \n \ndiff --git a/config/hooks/stop-validator.py b/config/hooks/stop-validator.py\nindex c68f927..9550cd2 100755\n\n... [truncated - diff too long]",
  "existing_docs": [
    "docs/architecture.md",
    "docs/analysis-persistent-memory-for-harnesses.md",
    "docs/index.md",
    "docs/memory-integration-analysis.md",
    "docs/philosophy.md",
    "docs/audiobook-the-amnesiac-architect.md",
    "README.md",
    ".claude/MEMORIES.md"
  ],
  "instructions": "\nDOCUMENTATION UPDATE TASK\n\nA commit was just made in an repair/build session. Your job is to:\n\n1. Analyze the diff to understand what changed\n2. Determine which documentation files need updating\n3. Update the relevant docs to reflect the changes\n\nCOMMIT MESSAGE:\nfeat(compound): implement Phases 2-3 of Compound Memory System\n\n- Add compound-context-loader.py SessionStart hook for context injection\n- Register hook in settings.json (after session-snapshot, before read-docs)\n- Add /compound prompt to stop-validator (when code_changes_made=true)\n- Add async-tasks cleanup to session-snapshot (>7 days old)\n- Fix PID-scoped checkpoint cleanup with glob + is_pid_alive check\n\nThe compound memory system now has full infrastructure:\n- Phase 1: /compound skill for capturing solutions (done in 36fa2eb)\n- Phase 1.5: /build grep integration (done in 36fa2eb)\n- Phase 2: SessionStart context injection (this commit)\n- Phase 3: Automation prompts and cleanup (this commit)\n\nCo-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>\n\nEXISTING DOCUMENTATION FILES:\n- docs/architecture.md\n- docs/analysis-persistent-memory-for-harnesses.md\n- docs/index.md\n- docs/memory-integration-analysis.md\n- docs/philosophy.md\n- docs/audiobook-the-amnesiac-architect.md\n- README.md\n- .claude/MEMORIES.md\n\nDIFF CONTENT:\ncommit 17883fdd208098c7bd4242cdb61743bfacde3ae4\nAuthor: olivier-motium <243932812+olivier-motium@users.noreply.github.com>\nDate:   Sat Jan 31 01:36:24 2026 +0100\n\n    feat(compound): implement Phases 2-3 of Compound Memory System\n    \n    - Add compound-context-loader.py SessionStart hook for context injection\n    - Register hook in settings.json (after session-snapshot, before read-docs)\n    - Add /compound prompt to stop-validator (when code_changes_made=true)\n    - Add async-tasks cleanup to session-snapshot (>7 days old)\n    - Fix PID-scoped checkpoint cleanup with glob + is_pid_alive check\n    \n    The compound memory system now has full infrastructure:\n    - Phase 1: /compound skill for capturing solutions (done in 36fa2eb)\n    - Phase 1.5: /build grep integration (done in 36fa2eb)\n    - Phase 2: SessionStart context injection (this commit)\n    - Phase 3: Automation prompts and cleanup (this commit)\n    \n    Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>\n---\n config/hooks/_state.py                  |  24 ++++++--\n config/hooks/compound-context-loader.py | 103 ++++++++++++++++++++++++++++++++\n config/hooks/session-snapshot.py        |  22 +++++++\n config/hooks/stop-validator.py          |  16 +++++\n config/settings.json                    |  10 ++++\n 5 files changed, 171 insertions(+), 4 deletions(-)\n\ndiff --git a/config/hooks/_state.py b/config/hooks/_state.py\nindex a40531e..3c9afb7 100644\n--- a/config/hooks/_state.py\n+++ b/config/hooks/_state.py\n@@ -14,7 +14,7 @@ import os\n from datetime import datetime, timezone\n from pathlib import Path\n \n-from _common import is_state_expired, is_state_for_session\n+from _common import is_state_expired, is_state_for_session, is_pid_alive\n \n \n # ============================================================================\n@@ -491,10 +491,13 @@ def cleanup_expired_state(cwd: str, current_session_id: str = \"\") -> list[str]:\n \n \n def cleanup_checkpoint_only(cwd: str) -> list[str]:\n-    \"\"\"Delete ONLY the completion checkpoint file. Leave mode state intact.\n+    \"\"\"Delete ONLY the completion checkpoint file(s). Leave mode state intact.\n \n     This is the sticky session replacement for cleanup_autonomous_state\n     at task boundaries.\n+\n+    Handles PID-scoped checkpoint files (e.g., completion-checkpoint.12345.json)\n+    by checking if the PID is still alive before deleting.\n     \"\"\"\n     deleted = []\n     if not cwd:\n@@ -504,8 +507,21 @@ def cleanup_checkpoint_only(cwd: str) -> list[str]:\n     if not claude_dir.exists():\n         return deleted\n \n-    checkpoint_path = claude_dir / \"completion-checkpoint.json\"\n-    if checkpoint_path.exists():\n+    # Use glob to find all checkpoint variants (including PID-scoped)\n+    for checkpoint_path in claude_dir.glob(\"completion-checkpoint*.json\"):\n+        name = checkpoint_path.name\n+\n+        # Check for PID-scoped files (e.g., completion-checkpoint.12345.json)\n+        if name != \"completion-checkpoint.json\":\n+            try:\n+                # Extract PID from filename\n+                pid_str = name.replace(\"completion-checkpoint.\", \"\").replace(\".json\", \"\")\n+                pid = int(pid_str)\n+                if is_pid_alive(pid):\n+                    continue  # Skip - belongs to active session\n+            except ValueError:\n+                pass  # Not a valid PID format, safe to delete\n+\n         try:\n             checkpoint_path.unlink()\n             deleted.append(str(checkpoint_path))\ndiff --git a/config/hooks/compound-context-loader.py b/config/hooks/compound-context-loader.py\nnew file mode 100644\nindex 0000000..d55abbf\n--- /dev/null\n+++ b/config/hooks/compound-context-loader.py\n@@ -0,0 +1,103 @@\n+#!/usr/bin/env python3\n+\"\"\"\n+Compound Context Loader - SessionStart Hook\n+\n+Injects relevant solutions from docs/solutions/ at session start.\n+Gracefully exits if no solutions directory exists.\n+\n+Part of the Compound Memory System that enables cross-session learning.\n+\"\"\"\n+\n+from __future__ import annotations\n+\n+import json\n+import sys\n+from pathlib import Path\n+\n+# Add hooks directory to path for shared imports\n+sys.path.insert(0, str(Path(__file__).parent))\n+\n+from _common import log_debug\n+\n+MAX_SOLUTIONS = 2\n+MAX_CHARS = 2000\n+\n+\n+def main():\n+    input_data = json.loads(sys.stdin.read() or \"{}\")\n+    cwd = input_data.get(\"cwd\", \"\")\n+\n+    if not cwd:\n+        sys.exit(0)\n+\n+    solutions_dir = Path(cwd) / \"docs\" / \"solutions\"\n+    if not solutions_dir.exists():\n+        sys.exit(0)\n+\n+    # Find all solution markdown files\n+    solution_files = []\n+    for md_file in solutions_dir.rglob(\"*.md\"):\n+        # Skip .gitkeep and other non-solution files\n+        if md_file.name.startswith(\".\") or md_file.name == \".gitkeep\":\n+            continue\n+        try:\n+            mtime = md_file.stat().st_mtime\n+            solution_files.append((mtime, md_file))\n+        except OSError:\n+            continue\n+\n+    if not solution_files:\n+        log_debug(\n+            \"No solution files found\",\n+            hook_name=\"compound-context-loader\",\n+            parsed_data={\"solutions_dir\": str(solutions_dir)},\n+        )\n+        sys.exit(0)\n+\n+    # Sort by mtime (most recent first), take top N\n+    solution_files.sort(reverse=True, key=lambda x: x[0])\n+    recent = solution_files[:MAX_SOLUTIONS]\n+\n+    # Build context summary\n+    summaries = []\n+    for _, path in recent:\n+        try:\n+            content = path.read_text()\n+            # Extract title from frontmatter or first heading\n+            title = path.stem.replace(\"-\", \" \").title()\n+            for line in content.split(\"\\n\"):\n+                if line.startswith(\"title:\"):\n+                    title = line.split(\":\", 1)[1].strip().strip(\"\\\"'\")\n+                    break\n+                if line.startswith(\"# \"):\n+                    title = line[2:].strip()\n+                    break\n+\n+            category = path.parent.name\n+            summaries.append(f\"- [{category}] {title}\")\n+        except (IOError, OSError):\n+            continue\n+\n+    if not summaries:\n+        sys.exit(0)\n+\n+    # Format output (plain text, not JSON - SessionStart hooks use plain print)\n+    output = \"[compound-context-loader] Recent solutions in docs/solutions/:\\n\"\n+    output += \"\\n\".join(summaries)\n+    output += \"\\n\\nRun `grep -riwl 'keyword' docs/solutions/` to find relevant fixes.\"\n+\n+    if len(output) > MAX_CHARS:\n+        output = output[: MAX_CHARS - 3] + \"...\"\n+\n+    log_debug(\n+        \"Injecting solution context\",\n+        hook_name=\"compound-context-loader\",\n+        parsed_data={\"solutions_count\": len(summaries), \"output_chars\": len(output)},\n+    )\n+\n+    print(output)\n+    sys.exit(0)\n+\n+\n+if __name__ == \"__main__\":\n+    main()\ndiff --git a/config/hooks/session-snapshot.py b/config/hooks/session-snapshot.py\nindex 9451a6e..bb25f08 100755\n--- a/config/hooks/session-snapshot.py\n+++ b/config/hooks/session-snapshot.py\n@@ -169,6 +169,28 @@ def main():\n     except ImportError:\n         pass  # worktree-manager not available\n \n+    # 5. Clean up stale async-tasks files (older than 7 days)\n+    import time\n+\n+    async_tasks_dir = claude_dir / \"async-tasks\"\n+    if async_tasks_dir.exists():\n+        seven_days_ago = time.time() - (7 * 24 * 60 * 60)\n+        cleaned_tasks = []\n+        for task_file in async_tasks_dir.glob(\"*.json\"):\n+            try:\n+                if task_file.stat().st_mtime < seven_days_ago:\n+                    task_file.unlink()\n+                    cleaned_tasks.append(task_file.name)\n+            except (IOError, OSError):\n+                continue\n+        if cleaned_tasks:\n+            log_debug(\n+                \"Cleaned up stale async-tasks\",\n+                hook_name=\"session-snapshot\",\n+                parsed_data={\"cleaned\": len(cleaned_tasks)},\n+            )\n+            print(f\"[session-snapshot] Cleaned up {len(cleaned_tasks)} stale async-task(s).\")\n+\n     sys.exit(0)\n \n \ndiff --git a/config/hooks/stop-validator.py b/config/hooks/stop-validator.py\nindex c68f927..9550cd2 100755\n\n... [truncated - diff too long]\n\nINSTRUCTIONS:\n- Only update docs that are actually affected by this change\n- Keep updates concise and accurate\n- Don't add unnecessary documentation\n- If the change is purely code (no architectural/API changes), you may skip doc updates\n- Focus on: API changes, new features, architectural decisions, configuration changes\n\nUse the /heavy skill if you need multiple perspectives on what to document.\n"
}